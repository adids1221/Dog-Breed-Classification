{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f8a3182",
   "metadata": {},
   "source": [
    "# iStock Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51475b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888b3629",
   "metadata": {},
   "source": [
    "## Import breeds from txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6dbf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_breeds = []\n",
    "\n",
    "path = os.getcwd()\n",
    "my_file = open(os.path.join(path ,\"Breed_iStock.txt\"), \"r\")\n",
    "content = my_file.read()\n",
    "content_list = content.split(\"\\n\")\n",
    "my_file.close()\n",
    "\n",
    "for breed in content_list:\n",
    "        word = breed.replace(\"_\", \" \").replace(\"-\", \" \")\n",
    "        word= word[:1].upper() + word[1:]\n",
    "        final_breeds.append(word)\n",
    "        \n",
    "print(final_breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfc5a8",
   "metadata": {},
   "source": [
    "## Selenium driver setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73974cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "s = Service('C:/Users/Asus/Documents/WebDriver/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=s)\n",
    "driver.get('https://www.istockphoto.com/')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_URL = \"https://www.istockphoto.com/search/2/image?phrase=\"\n",
    "main_URL = \"https://www.istockphoto.com/\"\n",
    "page_url = \"&page=\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e97f52",
   "metadata": {},
   "source": [
    "## iStock Crawling/Scraping  Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39fde59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(query):\n",
    "    if not os.path.exists(os.getcwd() + '/' + query):\n",
    "        path = os.getcwd()\n",
    "        path = os.path.join(path, query)\n",
    "        os.mkdir(path)\n",
    "        print(query + \" Folder Created\")\n",
    "    else:\n",
    "        print(query + \" Folder Already Exist\")\n",
    "        \n",
    "def save_images(images, query):\n",
    "    counter = 0\n",
    "    path = os.getcwd()\n",
    "    path = os.path.join(path, query)\n",
    "    for img in images:\n",
    "        save_as = os.path.join(path ,query + str(counter) +'.jpg')\n",
    "        try:\n",
    "            wget.download(img, save_as)\n",
    "        except Exception as e:\n",
    "            print(\"Could not download file %s\"%(img))\n",
    "            print(e)\n",
    "            continue\n",
    "        counter += 1\n",
    "    \n",
    "    print(\"%s Images Saved! | Total of: %s Images\" %(query,counter))\n",
    "    \n",
    "def save_single_images(img, query):\n",
    "    counter = 0\n",
    "    path = os.getcwd()\n",
    "    path = os.path.join(path, query)\n",
    "    save_as = os.path.join(path ,query + str(counter) +'.jpg')\n",
    "    print(img)\n",
    "    wget.download(img, save_as)\n",
    "    \n",
    "    print(\"%s Images Saved!\" %(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d25f2",
   "metadata": {},
   "source": [
    "## Use The Automation For Each Breed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ccddcd",
   "metadata": {},
   "source": [
    "#### In this automation we used Selenium and BeautifulSoup combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb2b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "for breed in final_breeds:\n",
    "    \n",
    "    print(\"Search images for: \" + breed)\n",
    "    img_urls = []\n",
    "    img_download_links = []\n",
    "    query = breed\n",
    "    page = driver.get(search_URL + query + page_url + \"1\") \n",
    "\n",
    "    time.sleep(random.randint(3,6))\n",
    "    page_source = driver.page_source\n",
    "    soup = bs(page_source, 'html.parser')\n",
    "    total_pages = soup.find('span',{'class':'PaginationRow-module__lastPage___FVgO3'}).text\n",
    "    print(\"Total pages to run: %s\"%(total_pages))\n",
    "    \n",
    "    for i in range(1, int(total_pages)+1):\n",
    "        page_source = driver.page_source\n",
    "        soup = bs(page_source, 'html.parser')\n",
    "        links = soup.find_all('img',{'class':'MosaicAsset-module__thumb___tdc6z'})\n",
    "        for link in links:\n",
    "            img_download_links.append(link['src'])\n",
    "        print(\"Images: %s\"%(len(img_download_links)))\n",
    "        if(len(img_download_links) > 12000):\n",
    "            break\n",
    "        time.sleep(random.randint(2,4))\n",
    "        page = driver.get(search_URL + query + page_url + str(i+1))\n",
    "    \n",
    "    folder_name = query + \"iStock\"\n",
    "    #create path if dosent exsist\n",
    "    create_folder(folder_name)\n",
    "    \n",
    "    #save the images\n",
    "    save_images(img_download_links,folder_name)\n",
    "    print(\"Donwload for %s finished, Total of %s images!\"%(breed,len(img_download_links)))\n",
    "    #save_single_images(img_download_links[0], query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849ff772",
   "metadata": {},
   "source": [
    "### In this project all the data came from scrapping and the crawling is used for educational purpose only."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
