{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4d9ef9f",
   "metadata": {},
   "source": [
    "# Data cleanning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40bc9f1",
   "metadata": {},
   "source": [
    "In this notebook we will use few filters/techniques to clean images data so it will be ready for modeling.\n",
    "\n",
    "Keep in mind that these cleanning techniques are very picky and they generally suits very large datasets whose ready to lose about 50% of the data in total.\n",
    "Our approach was to crawl as much data as possible (even trash data) and then to clean it aggressively.\n",
    "\n",
    "At first step,\n",
    "we will use ResNet50 network to clean all the images that there without dogs. This step is very important because there is no point training the model on images without dogs.\n",
    "(The ResNet50 cleanning notebook can be found at: https://github.com/adids1221/Dog-Breed-Classification/blob/main/data_cleaning/ResNet50%20Data%20Cleaning.ipynb) \n",
    "\n",
    "At the second step,\n",
    "we noticed that big part of our images were drawings, and not photos, which probably will affect the model and disturb it when training, thus, we decided to detect the drawing with entropy.\n",
    "We found out that in avarage, drawing's entropy is way lower than real photo's entropy, so we made a function that detects every images from the dataset whose has entropy below 4.3 and deleting it.\n",
    "We also noticed that photos with dogs on a uniform backgroud tend to have the same entropy value as drawings, so, we did a little trick which is actually to eliminate the most frequent value in all images, and only then calculate the entoropy value (What it did is to \"remove\" the uniform backgroud from the photo because we assumed that the backgroud is the most frequent value/color in an image like that\".\n",
    "\n",
    "At third step, \n",
    "We calculated the avarage outliers amount for each class, how we did that?\n",
    "1.Calculate the mean of an image and flatten it\n",
    "2.Calculate the IQR 40-60 of that image\n",
    "3.Sum all IQRs values of all images of the class and devide by number of images of that class\n",
    "After we had the avarage outliers of a class we decided to eliminate some of the classes due proccessing power limitaion.\n",
    "We took into account the avarages distribution and the distribition of images count of each class.\n",
    "\n",
    "At forth step,\n",
    "We calculated and plotted the intensitiy distribution of the images for each class and also for the whole data itself. \n",
    "\n",
    "At fifth step,\n",
    "We deleted all the images of each class, whose have above the avarage outliers in comparision to the class avarage.\n",
    "\n",
    "At sixth step,\n",
    "We calculated and plotted the intensitiy distribution of the images for each class and also for the whole data itself after cleanning to check if we made a good job (the overall intesnitiy decreased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb53115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files   \n",
    "\n",
    "from tensorflow import keras \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import statistics\n",
    "import math\n",
    "from scipy.stats import iqr\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import statistics\n",
    "import math\n",
    "from scipy.stats import iqr\n",
    "import os\n",
    "import collections\n",
    "import operator\n",
    "from collections import OrderedDict\n",
    "from matplotlib.pyplot import figure, imshow, axis\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage.measure.entropy import shannon_entropy\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162a0a7b",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88978ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    return df\n",
    "\n",
    "def display_img(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    imgplot = plt.imshow(cv_rgb)\n",
    "    return imgplot\n",
    "\n",
    "def cal_average(num):\n",
    "    sum_num = 0\n",
    "    for t in num:\n",
    "        sum_num = sum_num + t           \n",
    "\n",
    "    avg = sum_num / len(num)\n",
    "    return avg\n",
    "\n",
    "def plot_image_intensity_distb(img_path):\n",
    "    im = cv2.imread(img_path)\n",
    "    # calculate mean value from RGB channels and flatten to 1D array\n",
    "    vals = im.mean(axis=2).flatten()\n",
    "    # plot histogram with 255 bins\n",
    "    b, bins, patches = plt.hist(vals, 255)\n",
    "    plt.xlim([0,255])\n",
    "    plt.show()\n",
    "    display_img(img_path)\n",
    "\n",
    "def plot_image_intensity_rgb(df_image, label):\n",
    "    img = cv2.imread(df_image)\n",
    "    color = ('b','g','r')\n",
    "    for i,col in enumerate(color):\n",
    "        histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "        plt.plot(histr,color = col)\n",
    "        plt.xlim([0,256])\n",
    "        \n",
    "    print(dog_names[np.argmax(label)])\n",
    "    print(img.shape)\n",
    "    plt.show()\n",
    "    #plt.imshow(img)\n",
    "    display_img(df_image)\n",
    "    \n",
    "def plot_class_intensity_distb(path_to_class_folder):\n",
    "    vals=[]\n",
    "    imgs_path = np.array(glob(f\"{path_to_class_folder}/*\"))\n",
    "    for img in imgs_path:\n",
    "        im=cv2.imread(img)\n",
    "        im=cv2.resize(im,(200,200))\n",
    "        vals.append(im.mean(axis=2).flatten())\n",
    "    summed_arr=np.sum(vals,axis=0)\n",
    "    summed_arr=summed_arr/len(imgs_path)\n",
    "    b, bins, patches = plt.hist(summed_arr, 255)\n",
    "    plt.xlim([0,255])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#plot all classes intensity ditb, save image, and return an array (summed an normalized) of all data distb\n",
    "def plot_class_intensity_distb1(path_to_father_folder):\n",
    "    classes = np.array(glob(f\"{path_to_father_folder}/*\"))\n",
    "    fig = plt.figure(figsize=(12,18), dpi= 100, facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "    vals=[]\n",
    "    avarage_all_classes_list=[]\n",
    "    dirname = os.path.basename(classes[0])\n",
    "\n",
    "    for i in range(1, 13):\n",
    "        summed_arr=return_class_intensity_array(classes[i-1])\n",
    "        avarage_all_classes_list.append(summed_arr)\n",
    "        print(\"done\"+ (classes[i-1]))\n",
    "\n",
    "        dirname = os.path.basename(classes[i-1])\n",
    "        plt.subplot(4, 3, i)\n",
    "        b, bins, patches = plt.hist(summed_arr, 255)\n",
    "        plt.xlim([0,255])\n",
    "        plt.title(dirname)\n",
    "        plt.savefig('EMG {0}.jpg'.format(i))\n",
    "\n",
    "    summed_classes_arr=np.sum(avarage_all_classes_list,axis=0)        \n",
    "    summed_classes_arr=summed_classes_arr/len(avarage_all_classes_list)\n",
    "    plt.show()\n",
    "    return summed_classes_arr   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1a80836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function returns how many outliers are in an image\n",
    "def find_img_intensity_iqr_40_60(img_path):\n",
    "    im = cv2.imread(img_path)\n",
    "    #print(img_path)\n",
    "    # calculate mean value from RGB channels and flatten to 1D array\n",
    "    vals = im.mean(axis=2).flatten()\n",
    "    iqr_image=iqr(vals,rng=(40, 60))\n",
    "    return iqr_image\n",
    "        \n",
    "    \n",
    "#function returns the avarge iqr of a class \n",
    "def iqrs_average_of_a_class(folder_path):\n",
    "    imgs_mean_vals=[]\n",
    "    imgs_path = np.array(glob(f\"{folder_path}/*\"))\n",
    "    \n",
    "    for img in imgs_path:\n",
    "       # print(img)\n",
    "        iqr_single_img=find_img_intensity_iqr_40_60(img) #find single iqr of single image\n",
    "        imgs_mean_vals.append(int(iqr_single_img)) #append all iqr of all images in a list\n",
    "        \n",
    "    return sum(imgs_mean_vals) / len(imgs_mean_vals)\n",
    "\n",
    "\n",
    "#retuns paths of imgs that are above avarage + paths top 5 imgs with lowest iqr + paths of top 5 images with highest iqr\n",
    "def paths_of_img_that_are_above_iqr_average_of_a_class_and_two_lists(folder_path):\n",
    "    imgs_iqr_above_avarge_paths=[]\n",
    "    top_5_lowest_iqr_imgs={\"path_1\":255,\"path_2\":255,\"path_3\":255,\"path_4\":255,\"path_5\":255}\n",
    "    top_5_highest_iqr_imgs={\"path_1\":0,\"path_2\":0,\"path_3\":0,\"path_4\":0,\"path_5\":0}\n",
    "    \n",
    "    avarage=iqrs_average_of_a_class(folder_path)\n",
    "    \n",
    "    imgs_path = np.array(glob(f\"{folder_path}/*\"))\n",
    "    \n",
    "    for img in imgs_path:\n",
    "        iqr_single_img=find_img_intensity_iqr_40_60(img) #find single iqr of single image\n",
    "        if(iqr_single_img>avarage):\n",
    "            imgs_iqr_above_avarge_paths.append(img)\n",
    "            \n",
    "        for k,v in top_5_lowest_iqr_imgs.items(): #update 5 lowest list\n",
    "            if(iqr_single_img<v): #if the current iqr is smaller then the smallest, replace it\n",
    "                top_5_lowest_iqr_imgs[k]=iqr_single_img\n",
    "                top_5_lowest_iqr_imgs[img] = top_5_lowest_iqr_imgs.pop(k) #here we change the key, means, update the path\n",
    "                top_5_lowest_iqr_imgs=sort_dict(top_5_lowest_iqr_imgs) #here we sort the dict so next time it will be easier\n",
    "                break\n",
    "               \n",
    "        for k,v in top_5_highest_iqr_imgs.items():\n",
    "            if(iqr_single_img>v): #if the current iqr is smaller then the smallest, replace it\n",
    "                top_5_highest_iqr_imgs[k]=iqr_single_img\n",
    "                top_5_highest_iqr_imgs[img] = top_5_highest_iqr_imgs.pop(k) #here we change the key, means, update the path\n",
    "                top_5_highest_iqr_imgs=des_sort_dict(top_5_highest_iqr_imgs) #here we desending-sort the dict so next time it will be easier\n",
    "                print(\"\")\n",
    "                break\n",
    "    return imgs_iqr_above_avarge_paths, top_5_lowest_iqr_imgs, top_5_highest_iqr_imgs\n",
    " \n",
    "    \n",
    "#returns average iqr of X classes\n",
    "def retruns_avarge_iqr_of_x_classes(path_to_main_folder): #structure= path_to_main_folder->{{class a}->{1img_class_a,2img_class_a},{class b}->{1img_class_b,2img_class_b}\n",
    "    \n",
    "    avrages_dict={}\n",
    "    folders_path= np.array(glob(f\"{path_to_main_folder}/*\"))\n",
    "    \n",
    "    for folder in folders_path:\n",
    "        avrages_dict[(folder.rsplit(\"/\",maxsplit=1)[1])]=iqrs_average_of_a_class(folder)\n",
    "        print(avrages_dict)\n",
    "         \n",
    "    return avrages_dict\n",
    "\n",
    "\n",
    "def sort_dict(unsorted_dict):\n",
    "    sorted_tuples = sorted(unsorted_dict.items(), key=operator.itemgetter(1))\n",
    "    sorted_dict = OrderedDict()\n",
    "    for k, v in sorted_tuples:\n",
    "        sorted_dict[k] = v\n",
    "    return sorted_dict\n",
    "\n",
    "\n",
    "def des_sort_dict(unsorted_dict):\n",
    "    des_sorted_tuples = sorted(unsorted_dict.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    des_sorted_dict = OrderedDict()\n",
    "    for k, v in des_sorted_tuples:\n",
    "        des_sorted_dict[k] = v\n",
    "    return des_sorted_dict\n",
    " \n",
    "    \n",
    "#plot sorted dict\n",
    "def plot_dict(dic,to_sort=True):\n",
    "    if(to_sort==True):\n",
    "        sorted_dict=sort_dict(dic)\n",
    "    keys = sorted_dict.keys()\n",
    "    values = sorted_dict.values()\n",
    "    plt.figure(figsize=(35, 8))  # width:20, height:3\n",
    "    plt.ylabel(\"Avarage Outliers\", fontsize=30)\n",
    "    plt.bar(keys, sorted_dict.values(), align='center',width=0.7)\n",
    "\n",
    "    \n",
    "#plots images horizontally if you input list of \n",
    "def showImagesHorizontally(list_of_imgs_pahts, count=0 ):\n",
    "    fig = figure(figsize=(20, 20), dpi=80)\n",
    "    if (count ==0):\n",
    "        number_of_files=len(list_of_imgs_pahts)\n",
    "    else:\n",
    "        number_of_files = count\n",
    "    for i in range(number_of_files):\n",
    "        a=fig.add_subplot(1,number_of_files,i+1)\n",
    "        image = imread(list_of_imgs_pahts[i])\n",
    "        imshow(image,cmap='Greys_r')\n",
    "        axis('off')\n",
    "\n",
    "        \n",
    "def extract_paths_from_a_dic_and_return_as_files(dic):\n",
    "    list_of_files=[]\n",
    "    for k,v in dic.items():\n",
    "        list_of_files.append(cv2.imread(k))\n",
    "    return list_of_files\n",
    "\n",
    "\n",
    "def extract_paths_from_a_dic_and_return_as_list(dic):\n",
    "    list_of_paths=[]\n",
    "    for k,v in dic.items():\n",
    "         list_of_paths.append(k) \n",
    "    return list_of_paths\n",
    "\n",
    "\n",
    "def paths_of_drawings_of_a_class(path_to_class_folder):\n",
    "    img_path_list=[]\n",
    "    imgs_path = np.array(glob(f\"{path_to_class_folder}/*\"))\n",
    "    for img_path in imgs_path:\n",
    "        print(img_path)\n",
    "        img = cv2.imread(img_path)\n",
    "        valueToBeRemoved = np.bincount(img.flatten()).argmax() #most common value\n",
    "        myImg = [value for value in img.flatten() if value != valueToBeRemoved] #remove most common value\n",
    "        ent=shannon_entropy(myImg)\n",
    "        print(ent)\n",
    "        if(ent<4.3):\n",
    "            img_path_list.append(img_path)   \n",
    "    return img_path_list  \n",
    "\n",
    "\n",
    "def clean_drawings_from_all_classes(path_to_father_folder):\n",
    "    list_of_paths_to_remove=[]\n",
    "    classes = np.array(glob(f\"{path_to_father_folder}/*\"))\n",
    "    for breedClassPath in classes:\n",
    "        list_of_paths_to_remove.extend(paths_of_drawings_of_a_class(breedClassPath))\n",
    "    return list_of_paths_to_remove\n",
    "\n",
    "\n",
    "def img_delete(img_list):\n",
    "    counter = 0\n",
    "    for img in img_list:\n",
    "        try:\n",
    "            os.remove(img)\n",
    "            counter+=1\n",
    "        except:\n",
    "            print(\"There was an error deleting the file: %\"%(img))\n",
    "    \n",
    "def return_class_intensity_array(path_to_class_folder):\n",
    "    vals=[]\n",
    "    imgs_path = np.array(glob(f\"{path_to_class_folder}/*\"))\n",
    "    for img in imgs_path:\n",
    "        im=cv2.imread(img)\n",
    "        im=cv2.resize(im,(200,200))\n",
    "        vals.append(im.mean(axis=2).flatten())\n",
    "    summed_arr=np.sum(vals,axis=0)\n",
    "    summed_arr=summed_arr/len(imgs_path)\n",
    "    return summed_arr\n",
    "\n",
    "\n",
    "def return__list_of_paths_of_images_above_avg_ouliers_to_delete_plus_paths_to_best_and_wrost(father_dic_path):\n",
    "    classes_paths = np.array(glob(f\"{father_dic_path}/*\"))\n",
    "    images_paths_to_delete_that_are_above_avarage_of_all_classes=[]\n",
    "    five_images_paths_that_are_ABOVE_avarge_of_all_classes=[]\n",
    "    five_images_paths_that_are_BELOW_avarge_of_all_classes=[]\n",
    "\n",
    "    for class_path in classes_paths:\n",
    "            imgs_iqr_above_avarge_paths, top_5_lowest_iqr_imgs,top_5_highest_iqr_imgs=paths_of_img_that_are_above_iqr_average_of_a_class_and_two_lists(class_path)\n",
    "\n",
    "            images_paths_to_delete_that_are_above_avarage_of_all_classes.append(imgs_iqr_above_avarge_paths)\n",
    "            five_images_paths_that_are_ABOVE_avarge_of_all_classes.append(top_5_highest_iqr_imgs)\n",
    "            five_images_paths_that_are_BELOW_avarge_of_all_classes.append(top_5_lowest_iqr_imgs)\n",
    "\n",
    "    return images_paths_to_delete_that_are_above_avarage_of_all_classes,five_images_paths_that_are_ABOVE_avarge_of_all_classes,five_images_paths_that_are_BELOW_avarge_of_all_classes\n",
    "\n",
    "\n",
    "\n",
    "def plot_entp(image_path):\n",
    "    img = cv2.imread(image_path) #path to the image\n",
    "    fig = plt.figure(figsize=(25, 25), dpi=80)\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(RGB_img)\n",
    "\n",
    "    print(img.shape) # show dimension of image\n",
    "    dim1, dim2 = img.shape[0], img.shape[1]\n",
    "    num_channels = img.shape[2]\n",
    "\n",
    "\n",
    "    valueToBeRemoved = np.bincount(img.flatten()).argmax() #most common value -> delete \n",
    "    myList = [value for value in img.flatten() if value != valueToBeRemoved] #remove most common value\n",
    "\n",
    "    \n",
    "    #print(myList[0])\n",
    "    myList = np.array(RGB_img)\n",
    "    print(shannon_entropy(myList)) \n",
    "    \n",
    "    entr_img = entropy(RGB_img[:,:,0], disk(10))\n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "    plt.imshow(entr_img, cmap='viridis')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def save_list_to_a_file(list_):\n",
    "    with open('your_file.txt', 'w') as f:\n",
    "        for item in list_:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "            \n",
    "def return_list_of_lists_of_rows_from_a_df_and_lists_of_eow_labels(file_path):\n",
    "    labels=[]\n",
    "    df=load_csv(file_path)\n",
    "    df_list = df.values.tolist()\n",
    "    for i in range(len(df_list)):\n",
    "        labels.append(df_list[i][0])\n",
    "        del df_list[i][0]    \n",
    "    return df_list,labels \n",
    "    \n",
    "\n",
    "def create_stack_plot (df_list,labels):\n",
    "    x = list(range(1,30))\n",
    "    y = np.vstack(df_list)\n",
    "    pal = [\"#9bc363\", \"#0c9191\", \"#e3bc81\", \"#9b4065\",\"#482b58\"]\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    ax.stackplot(x, y, labels=labels,colors=pal, alpha=0.8)\n",
    "    \n",
    "    ax.legend(loc='upper left',prop={'size': 25})\n",
    "    ax.set_xlabel('Day',fontsize=20)\n",
    "    ax.set_ylabel('Time spent',fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96b08d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "father_folder_path=\"/Volumes/UNTITLED/Dataset-1/Dogs\"\n",
    "csv_path = 'C:/Users/Asus/Data Science Project'\n",
    "image_path=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5517ac9f",
   "metadata": {},
   "source": [
    "# Plot entropy without  most common value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac46c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_entp(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52585ac",
   "metadata": {},
   "source": [
    "# Detecting drawings at classes and deleting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawings_paths_list=clean_drawings_from_all_classes(father_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_delete(drawings_paths_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd569a",
   "metadata": {},
   "source": [
    "# Plot avarage outliers for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94bafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_x_classes_outliers_avarage=retruns_avarge_iqr_of_x_classes(father_folder_path)\n",
    "plot_dict(dict_of_x_classes_outliers_avarage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea80a41e",
   "metadata": {},
   "source": [
    "# Plot avarge class intensitiy distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e80b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_and_normilized_all_data_arr_distc=plot_class_intensity_distb1(father_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e5d64a",
   "metadata": {},
   "source": [
    "# Plot avarage all data intensitiy distribiution before cleanning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "3dd4f883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b, bins, patches = plt.hist(summed_and_normilized_all_data_arr_distc, 255)\n",
    "plt.xlim([0,255])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74132052",
   "metadata": {},
   "source": [
    "# Detect images with above avarage outliers + delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e08191",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_paths_to_delete_that_are_above_avarage_of_all_classes,\n",
    "five_images_paths_that_are_ABOVE_avarge_of_all_classes,\n",
    "five_images_paths_that_are_BELOW_avarge_of_all_classes=return__list_of_paths_of_images_above_avg_ouliers_to_delete_plus_paths_to_best_and_wrost(father_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c6530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the images\n",
    "for i in range(len(images_paths_to_delete_that_are_above_avarage_of_all_classes)):\n",
    "    img_delete(images_paths_to_delete_that_are_above_avarage_of_all_classes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6dbe7c",
   "metadata": {},
   "source": [
    "# Plot 5 images with least outliers and 5 with most outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d27632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "showImagesHorizontally(five_images_paths_that_are_ABOVE_avarge_of_all_classes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c35c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "showImagesHorizontally(five_images_paths_that_are_BELOW_avarge_of_all_classes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eabe789",
   "metadata": {},
   "source": [
    "# Plot avarage all data intensitiy distribiution after cleanning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6063c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_and_normilized_all_data_arr_distc=plot_class_intensity_distb1(father_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "be07e214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b, bins, patches = plt.hist(summed_and_normilized_all_data_arr_distc, 255)\n",
    "plt.xlim([0,255])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
